{
    "list": [
       {
          "name":"Implemented SOTA LLMs from Scratch",
          "url":"https://github.com/PolRF/LM",
          "desc":"Implemented state-of-the-art LLM architectures from scratch using PyTorch and Triton, including GQA, RoPE, GPT-2, GELU, MoE, KV Cache, and Alibi. Trained models with parameter sizes ranging from 117M to 2.3B on an 8xH100 GPU cluster. Open-sourced code and model weights."
       },
       {
          "name":"Chat-Based RAG for Legal Document Retrieval",
          "url":"https://github.com/PolRF/LM",
          "desc":"Developed a retrieval-augmented generation (RAG) system as a side project for Aldara, enabling access to legal documentation through a chat-based interface."
       }
    ]
 }